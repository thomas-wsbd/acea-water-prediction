{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from geopandas.tools import geocode\n",
    "import time\n",
    "import os, json, urllib, requests, webbrowser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database</th>\n",
       "      <th>Description</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aquifer_Auser</td>\n",
       "      <td>Information about the Auser aquifer. This wate...</td>\n",
       "      <td>Depth_to_Groundwater_SAL, Depth_to_Groundwater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Water_Spring_Amiata</td>\n",
       "      <td>Information about the Amiata aquifer. This aqu...</td>\n",
       "      <td>Flow_Rate_Bugnano, Flow_Rate_Arbure,\\n Flow_Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aquifer_Petrignano</td>\n",
       "      <td>Information about Petrignano aquifer. \\nIt is ...</td>\n",
       "      <td>Depth_to_Groundwater_P24,\\n Depth_to_Groundwat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aquifer_Doganella</td>\n",
       "      <td>Information about Doganella aquifer. The Dogan...</td>\n",
       "      <td>Depth_to_Groundwater_Pozzo_1, Depth_to_Groundw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aquifer_Luco</td>\n",
       "      <td>Information about Luco aquifer. It is an under...</td>\n",
       "      <td>Depth_to_Groundwater_Podere_Casetta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Database                                        Description  \\\n",
       "0        Aquifer_Auser  Information about the Auser aquifer. This wate...   \n",
       "1  Water_Spring_Amiata  Information about the Amiata aquifer. This aqu...   \n",
       "2   Aquifer_Petrignano  Information about Petrignano aquifer. \\nIt is ...   \n",
       "3    Aquifer_Doganella  Information about Doganella aquifer. The Dogan...   \n",
       "4        Aquifer_Luco   Information about Luco aquifer. It is an under...   \n",
       "\n",
       "                                              Output  \n",
       "0  Depth_to_Groundwater_SAL, Depth_to_Groundwater...  \n",
       "1  Flow_Rate_Bugnano, Flow_Rate_Arbure,\\n Flow_Ra...  \n",
       "2  Depth_to_Groundwater_P24,\\n Depth_to_Groundwat...  \n",
       "3  Depth_to_Groundwater_Pozzo_1, Depth_to_Groundw...  \n",
       "4                Depth_to_Groundwater_Podere_Casetta  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = pd.read_excel('./data/datasets_description.xlsx')\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect all geolocations of header names\n",
    "\n",
    "# todo: manually check and fix, some don't seem correct (Laghetto Verde should prob be: 44.827716,7.0187831)\n",
    "if os.path.exists('./data/geolocations.pckl'):\n",
    "    gdfs = pd.read_pickle('./data/geolocations.pckl')\n",
    "else:\n",
    "\n",
    "    cols = []\n",
    "    for file in glob.glob('./data/*.csv'):\n",
    "        df = pd.read_csv(file)\n",
    "        [cols.append(c) for c in df.columns]\n",
    "    cols = [c for c in set(cols) if 'Depth' not in c and 'Flow_Rate' not in c and 'Volume' not in c and 'Lake_Level' not in c]\n",
    "    cols = set(cols) - set(['Date'])\n",
    "    cols = [c.replace('Rainfall', '').replace('Temperature', '').replace('Hydrometry', '').replace('_', ' ').strip() for c in cols]\n",
    "    places = cols\n",
    "    places = set(places)\n",
    "\n",
    "    locs = [\"{}, Italy\".format(name) for name in places]\n",
    "    gdfs = []\n",
    "\n",
    "    gdfs = geocode(list(locs))\n",
    "\n",
    "    gdfs['place'] = places\n",
    "    gdfs.to_pickle('./data/geolocations.pckl')\n",
    "    gdfs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# collect some relevant metrics from nasa POWER\n",
    "\n",
    "output = \"JSON\"\n",
    "locations = [gdfs.geometry.values]\n",
    "\n",
    "output_folder = r'./data/nasa-power'\n",
    "params = 'QV2M,RH2M,PS,PRECTOT,T2M_RANGE,T2MDEW,T2MWET,WS10M_RANGE,WS50M_RANGE'\n",
    "base_url = \"https://power.larc.nasa.gov/cgi-bin/v1/DataAccess.py?request=execute&identifier=SinglePoint&tempAverage=DAILY&parameters={}&startDate=20000101&endDate=20210101&lat={latitude}&lon={longitude}&outputList={output}&userCommunity=SSE\"\n",
    "gdfs['longitude'] = gdfs.geometry.x\n",
    "gdfs['latitude'] = gdfs.geometry.y\n",
    "\n",
    "for i, row in gdfs.iloc[:].iterrows():\n",
    "    longitude = row.longitude\n",
    "    latitude = row.latitude\n",
    "    api_request_url = base_url.format(params, longitude=longitude, latitude=latitude, output=output.upper())\n",
    "\n",
    "    json_response = json.loads(requests.get(api_request_url).content.decode('utf-8'))\n",
    "\n",
    "    # Selects the file URL from the JSON response\n",
    "    csv_request_url = json_response['outputs'][output.lower()]\n",
    "\n",
    "    # Download File to Folder\n",
    "    output_file_location = os.path.join(output_folder, row.place)+'.json'\n",
    "    urllib.request.urlretrieve(csv_request_url, output_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for f in glob.glob('./data/nasa-power/*.json'):\n",
    "    with open(f) as file:\n",
    "        data = json.load(file)\n",
    "    df = pd.DataFrame(data['features'][0]['properties']['parameter'])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.to_pickle(f.replace('.json', '.pckl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}